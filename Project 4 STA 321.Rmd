---
title: "Seattle Weather Time Series"
author: "Ryan Lebo"
date: "2024-12-10"
output: 
  html_document:
    toc: yes
    toc_depth: 4
    toc_float: yes
    fig_width: 4
    fig_caption: yes
    number_sections: yes
    toc_collapsed: yes
    code_folding: hide
    code_download: yes
    smooth_scroll: yes
    theme: lumen
  word_document:
    toc: yes
    toc_depth: 4
    fig_caption: yes
    keep_md: yes
  pdf_document:
    toc: yes
    toc_depth: 4
    fig_caption: yes
    number_sections: yes
    fig_width: 3
    fig_height: 3
editor_options:
  chunk_output_type: inline
slways_allow_html: true
---

```{=html}

<style type="text/css">

/* Cascading Style Sheets (CSS) is a stylesheet language used to describe the presentation of a document written in HTML or XML. it is a simple mechanism for adding style (e.g., fonts, colors, spacing) to Web documents. */

h1.title {  /* Title - font specifications of the report title */
  font-size: 24px;
  color: DarkRed;
  text-align: center;
  font-family: "Gill Sans", sans-serif;
}
h4.author { /* Header 4 - font specifications for authors  */
  font-size: 20px;
  font-family: system-ui;
  color: DarkRed;
  text-align: center;
}
h4.date { /* Header 4 - font specifications for the date  */
  font-size: 18px;
  font-family: system-ui;
  color: DarkBlue;
  text-align: center;
}
h1 { /* Header 1 - font specifications for level 1 section title  */
    font-size: 22px;
    font-family: "Times New Roman", Times, serif;
    color: navy;
    text-align: center;
}
h2 { /* Header 2 - font specifications for level 2 section title */
    font-size: 20px;
    font-family: "Times New Roman", Times, serif;
    color: navy;
    text-align: left;
}

h3 { /* Header 3 - font specifications of level 3 section title  */
    font-size: 18px;
    font-family: "Times New Roman", Times, serif;
    color: navy;
    text-align: left;
}

h4 { /* Header 4 - font specifications of level 4 section title  */
    font-size: 18px;
    font-family: "Times New Roman", Times, serif;
    color: darkred;
    text-align: left;
}

body { background-color:white; }

.highlightme { background-color:yellow; }

p { background-color:white; }

</style>
```
```{r setup, include=FALSE}
# Detect, install, and load packages if needed.
if (!require("knitr")) {
   install.packages("knitr")
   library(knitr)
}
if (!require("leaflet")) {
   install.packages("leaflet")
   library(leaflet)
}
if (!require("EnvStats")) {
   install.packages("EnvStats")
   library(EnvStats)
}
if (!require("MASS")) {
   install.packages("MASS")
   library(MASS)
}
if (!require("phytools")) {
   install.packages("phytools")
   library(phytools)
}
if (!require("mlbench")) {
   install.packages("mlbench")
   library(mlbench)
}
if (!require("pander")) {
   install.packages("pander")
   library(pander)
}
if (!require("ISwR")) {
   install.packages("ISwR")
   library(ISwR)
}
if (!require("ggplot2")) {
   install.packages("ggplot2")
   library(ggplot2)
}
if (!require("forecast")) {
   install.packages("forecast")
   library(forecast)
}
knitr::opts_chunk$set(echo = FALSE,  
                   warning = FALSE,  
                                     
                   message = FALSE,  
                   results = TRUE,  
                   comment = FALSE   
                      )   
```

```{r}
s_weath <- read.csv("https://raw.githubusercontent.com/RyanLebo/STA-321/refs/heads/main/seattle_weather.csv", header = TRUE)

```

# Introduction
In this project we want to find a time series with both trend and seasonality. We used a Seattle weather data set and are going to use the 160 most recent observations. We will look to fit three types of smoothing models. These models are simple exponential model, Holt models, and  Holt-Winter’s models. We will also look at visualizations for this.




## Data Description

* Month- Month of the year (in numbers. Ex: 1-Jan, 2-Feb...)
* Year- The year it was
* LowTemp- Lowest temperature 
* HighTemp- Highest temperature 
* WarmestMin- The lowest warm temperature 
* ColdestHigh- The highest cold temperature 
* AveMin-The average minimum temperature
* AveMax- The average maximum temperature
* meanTemp- The mean temperature
* TotPrecip- The total precipitation
* TotSnow- The total snow
* Max24hrPrecip- The maximum amount of precipitation in 24 hours

## Research Question

The goal of the analysis is to use time series to make conclusions on the mean temperature in Seattle for the next year based on this data set.

## Data turned into Smoothing Models

```{r}
sub_weath <- tail(s_weath, 160)
train.weath = sub_weath$meanTemp[1:148]
test.sea = sub_weath$meanTemp[149:160]

sea.weath = ts(train.weath, start=c(2000, 1), frequency=12)

fit1 = ses(sea.weath, h=12)
fit2 = holt(sea.weath, initial="optimal", h=12)
fit3 = holt(sea.weath, damped=TRUE, h=12)
fit4 = holt(sea.weath, exponential=TRUE, damped=TRUE, h=12)
fit5 = hw(sea.weath, h=12, seasonal="additive")
fit6 = hw(sea.weath, h=12, seasonal="multiplicative")
fit7 = hw(sea.weath, h=12, seasonal="additive", damped=TRUE)
fit8 = hw(sea.weath, h=12, seasonal="multiplicative", damped=TRUE)



```

We want to look at only the most recent data and narrowed it down to the last 160 observations to be productive. We made a test and training data set then for the project. There is only 12 observations in the testing data set and 148 in the training set. We then wanted top put the data into smoothing models to then test them for accuracy measures later on. 



# Accuracy Measures for training data

We get many accuracy values to see which model is best for our data. 

```{r}
accuracy.table = round(rbind(accuracy(fit1), accuracy(fit2), accuracy(fit3), accuracy(fit4),
                             accuracy(fit5), accuracy(fit6), accuracy(fit7), accuracy(fit8)),4)
row.names(accuracy.table)=c("SES","Holt Linear","Holt Add. Damped", "Holt Exp. Damped",
                            "HW Add.","HW Exp.","HW Add. Damp", "HW Exp. Damp")
kable(accuracy.table, caption = "The accuracy measures of various exponential smoothing models 
      based on the training data")

```

We see from the output above that HW Add Damp is the best fit for our data due to how it has the lowest average values of all the values above. For ACF1 it is a relatively low value meaning that residual autocorrelation is not a concern. 


## Visualization

We are now visualizing the original time series data and forecast results from different smoothing models

```{r fig.align='center',fig.width=6, fig.height=6.5, fig.cap="Case study: Comparing various exponential smoothing models."}
par(mfrow=c(2,1), mar=c(3,4,3,1))

pred.id = 149:160
plot(1:148, train.weath, lwd=2,type="o", ylab="MeanTemp", xlab="", 
     xlim=c(1,170), ylim=c(30, 90), cex=0.3,
     main="Non-seasonal Smoothing Models")
lines(pred.id, fit1$mean, col="red")
lines(pred.id, fit2$mean, col="blue")
lines(pred.id, fit3$mean, col="purple")
lines(pred.id, fit4$mean, col="navy")
##
points(pred.id, fit1$mean, pch=16, col="red", cex = 0.5)
points(pred.id, fit2$mean, pch=17, col="blue", cex = 0.5)
points(pred.id, fit3$mean, pch=19, col="purple", cex = 0.5)
points(pred.id, fit4$mean, pch=21, col="navy", cex = 0.5)
#points(fit0, col="black", pch=1)
legend("bottomright", lty=1, col=c("red","blue","purple", "navy"),pch=c(16,17,19,21),
   c("SES","Holt Linear","Holt Linear Damped", "Holt Multiplicative Damped"), 
   cex = 0.7, bty="n")

plot(1:148, train.weath, lwd=2,type="o", ylab="MeanTemp", xlab="", 
     xlim=c(1,170), ylim=c(30, 90), cex=0.3,
     main="Holt-Winterd Trend and Seasonal Smoothing Models")
lines(pred.id, fit5$mean, col="red")
lines(pred.id, fit6$mean, col="blue")
lines(pred.id, fit7$mean, col="purple")
lines(pred.id, fit8$mean, col="navy")

points(pred.id, fit5$mean, pch=16, col="red", cex = 0.5)
points(pred.id, fit6$mean, pch=17, col="blue", cex = 0.5)
points(pred.id, fit7$mean, pch=19, col="purple", cex = 0.5)
points(pred.id, fit8$mean, pch=21, col="navy", cex = 0.5)
###
legend("bottomright", lty=1, col=c("red","blue","purple", "navy"),pch=c(16,17,19,21),
   c("HW Additive","HW Multiplicative","HW Additive Damped", "HW Multiplicative Damped"), 
   cex = 0.7, bty="n")

```

We see from the above visual that HW’s linear trend with an additive damped seasonal model is the best fit. This matches up with the accuracy measures we talked about before. It performed well due to how it does not have a wide prediction band. 

# Accuracy Measures for testing data

We saw that the visualization and our training data showed us that HW Add Damp is the appropriate model. To make a real life forecast of our data we need to use the whole data set with all 160 recent observations. 

```{r}

acc.fun = function(test.data, mod.obj){
  PE=100*(test.data-mod.obj$mean)/mod.obj$mean
  MAPE = mean(abs(PE))
  ###
  E=test.data-mod.obj$mean
  MSE=mean(E^2)
  ###
  accuracy.metric=c(MSE=MSE, MAPE=MAPE)
  accuracy.metric
  
}


```

```{r}
pred.accuracy = rbind(SES =acc.fun(test.data=test.sea, mod.obj=fit1),
                      Holt.Add =acc.fun(test.data=test.sea, mod.obj=fit2),
                      Holt.Add.Damp =acc.fun(test.data=test.sea, mod.obj=fit3),
                      Holt.Exp =acc.fun(test.data=test.sea, mod.obj=fit4),
                      HW.Add =acc.fun(test.data=test.sea, mod.obj=fit5),
                      HW.Exp =acc.fun(test.data=test.sea, mod.obj=fit6),
                      HW.Add.Damp =acc.fun(test.data=test.sea, mod.obj=fit7),
                      HW.Exp.Damp =acc.fun(test.data=test.sea, mod.obj=fit8))
kable(pred.accuracy, caption="The accuracy measures of various exponential smoothing models 
      based on the testing data")

```

Looking at the table we see that HW Add Damped is again the best model which is consistent to our conclusions made earlier in the project. HW.Exp has the lowest average values and HW.ADD.Damp has the second lowest. HW Add Damped is the best model that we have looked at due to MSE (585.04) and MAPE (40.44) both being one of the lowest average values out of the models. It also has the lowest average in the training data while HW.Exp has about the third best average for the training data. Which means that the  HW.Add.Damped has the best all around accuracy measures for both the training anf testing data.

# Final Model

Here we use the whole data set and refit it using smoothing parameters.

```{r}
s_weath <- read.csv("https://raw.githubusercontent.com/RyanLebo/STA-321/refs/heads/main/seattle_weather.csv", header = TRUE)
seattleweath=ts(s_weath$meanTemp[1:160], start=2000, frequency = 12)
final.model = hw(seattleweath,h=12, seasonal="additive") 
smoothing.parameter = final.model$model$par[1:3]
kable(smoothing.parameter, caption="Estimated values of the smoothing parameters in
      Holt-Winters linear trend with additive seasonality")

```

The output above shows a value of 0.156 for alpha. This indicates that the model places moderate weight on our recent observations.  For Gamma, 0.0001, since it is close to 0 it shows that seasonality patterns are stable. For Beta, 0.0001, since it is close to 0 it doesn't have importance to updating the trend based on our recent observations.


# Conclusion

The Seattle weather data set I used showed that the best model we could use was HW's linear trend using an additive damped seasonal model. We got this by splitting our data into a training data set and testing data set. We also saw from the accuracy measures and the visuals that the additive damped model from HW was the best model. For our final model we got gamma and beta values close to 0 so that showed seasonality patterns were stable and we do not need to update the trend. Our alpha was 0.156 which showed that the model placed some weight on our recent observations.

This project we made sure to look at the most recent 160 observations due to needing more than 100. We then used a frequency of 12 for the 12 months of the year.

Our performance metrics of MSE and MAPE showed that their values were the lowest. This meant that our predictors are closer to the true values and that our model has the most accurate forecast.        






